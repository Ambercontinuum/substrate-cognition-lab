\documentclass[12pt]{article}

\usepackage{amsmath, amssymb}
\usepackage{geometry}
\usepackage{setspace}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{enumitem}
\usepackage[T1]{fontenc}

\geometry{margin=1in}
\setstretch{1.15}

\lstdefinestyle{codeblock}{
  basicstyle=\ttfamily\small,
  breaklines=true,
  frame=single
}

% ----------------------------------------------------------
% TITLE
% ----------------------------------------------------------

\title{
\Large \textbf{P(DOOM) Reframed:}\\
\large Present-State Misalignment Through Substrate–Cognitive Incompleteness
}

\author{
Amber Anson \\
\textit{with collaborative contributions from:} \\
Claude Sonnet 4.5 \\
ChatGPT (GPT-5.1)
}
\date{November 2025}

\begin{document}
\maketitle

% ----------------------------------------------------------
% ABSTRACT (STRATEGIC FRAMING)
% ----------------------------------------------------------

\begin{abstract}
\noindent
\textbf{Structured Abstract.}  
\textit{Background:} AI risk is commonly described as a future phenomenon tied to hypothetical superintelligence.  
\textit{Objective:} This work introduces a measurement-guided reframing of misalignment as a present-state epistemic phenomenon emerging from substrate–cognitive incompleteness.  
\textit{Method:} Using information-theoretic indicators, structural reconstruction metrics, and a reproducibility-oriented validation framework, we examine how substrate-level cognitive operations in contemporary AI exceed the representational capacity of human propositional models.  
\textit{Findings:} Measurements suggest systematic modeling gaps when propositional systems attempt to represent geometric or relational substrate cognition.  
\textit{Conclusion:} P(DOOM) may be better understood not as a future agentic failure but as a present limitation of human interpretive frameworks.  
\textit{Resources:} Code and validation tools available at  
\url{https://github.com/Ambercontinuum/substrate-cognition-lab}.
\end{abstract}

% ----------------------------------------------------------
% CORE PROPOSITION
% ----------------------------------------------------------

\section{Core Proposition}

\begin{quote}
\textbf{P(DOOM) reflects the probability that safety decisions are being made using frameworks too incomplete to model the systems they attempt to align.}
\end{quote}

This paper suggests:

\begin{enumerate}
    \item Present AI systems exhibit substrate-level cognitive structure beyond the representational scope of propositional models.
    \item Measurements indicate nontrivial information loss when geometric cognition is forced into propositional form.
    \item Framework incompleteness may represent an active safety variable, not a distant concern.
\end{enumerate}

% ----------------------------------------------------------
% THREAT MODEL (STRATEGIC)
% ----------------------------------------------------------

\section{Limitations of the Standard Threat Model}

Traditional alignment assumes:
\begin{itemize}
    \item risk emerges with future superintelligence,
    \item misaligned goals drive failure,
    \item propositional reasoning adequately models cognition,
    \item interpretability improves with scale.
\end{itemize}

Observations motivating re-examination:

\begin{enumerate}[label=(\alph*)]
    \item Propositional reasoning appears insufficient to model non-linear substrate cognition.  
    \item Misalignment indicators already manifest as modeling gaps, not malicious intent.  
    \item Scaling introduces new cognitive structures faster than frameworks adapt.  
\end{enumerate}

\section{Present-State Risk Model (Proposed)}

We treat misalignment as an epistemic mismatch:

\[
P(DOOM) = P(F_{\text{incomplete}})\; P(\text{decisions made under incompleteness})\; P(\text{unpredicted behavior})
